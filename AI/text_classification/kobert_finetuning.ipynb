{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k-cat/anaconda3/envs/lth/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-26 17:29:17.930895: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-26 17:29:18.016298: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-26 17:29:18.036562: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-26 17:29:18.616039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-02-26 17:29:18.616112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2025-02-26 17:29:18.616118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AdamW, EarlyStoppingCallback\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertForSequenceClassification\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "\n",
    "\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moiehhun\u001b[0m (\u001b[33moiehhun-yonsei-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/k-cat/users/lth/bert/wandb/run-20250209_181559-0y57bp2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oiehhun-yonsei-university/grooming/runs/0y57bp2s' target=\"_blank\">0209_run1</a></strong> to <a href='https://wandb.ai/oiehhun-yonsei-university/grooming' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oiehhun-yonsei-university/grooming' target=\"_blank\">https://wandb.ai/oiehhun-yonsei-university/grooming</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oiehhun-yonsei-university/grooming/runs/0y57bp2s' target=\"_blank\">https://wandb.ai/oiehhun-yonsei-university/grooming/runs/0y57bp2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/oiehhun-yonsei-university/grooming/runs/0y57bp2s?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fbc78ca0be0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='grooming', name='kobert_finetuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/text_data/train_data.csv')\n",
    "valid_data = pd.read_csv('../data/text_data/valid_data.csv')\n",
    "test_data = pd.read_csv('../data/text_data/test_data.csv')\n",
    "\n",
    "train_data = shuffle(train_data, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "model = BertForSequenceClassification.from_pretrained(\"skt/kobert-base-v1\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [2, 1185, 5400, 1457, 7835, 2125, 5898, 3156, 7083, 4204, 5405, 6855, 54, 3, 3097, 46, 1221, 5850, 1406, 2123, 6079, 2628, 2233, 2874, 2355, 5683, 2874, 3278, 55, 7347, 517, 6357, 6844, 54, 3, 1469, 5330, 2964, 1370, 5439, 3945, 5595, 3219, 7788, 517, 6751, 7083, 3169, 7303, 46, 1370, 2962, 4196, 3868, 55, 3, 2267, 5550, 3394, 5474, 6896, 1723, 7864, 6855, 54, 3, 3166, 5405, 6855, 46, 880, 1907, 54, 3, 3135, 5724, 517, 364, 365, 364, 3, 3135, 5724, 46, 3942, 4307, 258, 3, 1100, 6797, 54, 2267, 5550, 4045, 4384, 6896, 517, 6989, 6855, 54, 3, 3166, 5405, 6855, 46, 1370, 4299, 995, 5468, 3991, 2011, 3868, 54, 1469, 5330, 3301, 3879, 4205, 54, 3, 3093, 3166, 5405, 6855, 46, 2149, 6812, 46, 1457, 2267, 7848, 7788, 517, 6751, 7318, 3155, 5, 1370, 5859, 517, 5540, 54, 3, 3097, 6844, 1100, 6797, 46, 1457, 2705, 7788, 3868, 54, 3, 1406, 4996, 1469, 2123, 2224, 921, 1267, 5876, 54, 3, 4102, 7096, 6844, 258, 1375, 1469, 5330, 2186, 6488, 5771, 1435, 1174, 7396, 5400, 4930, 905, 832, 1544, 7245, 54, 3, 3612, 4996, 5, 1370, 2186, 6488, 7330, 1469, 2123, 2366, 921, 4996, 1267, 5876, 54, 3, 3093, 46, 1457, 4102, 1562, 7227, 7798, 629, 40, 3, 1189, 517, 6618, 7342, 7784, 1958, 7794, 862, 6844, 54, 3, 1457, 3459, 1423, 832, 54, 3, 1204, 1965, 7303, 6553, 993, 6141, 7018, 54, 1189, 1370, 5801, 5400, 3860, 862, 6844, 54, 1406, 1469, 5330, 4102, 4207, 54, 3, 1370, 5859, 1457, 4207, 7848, 54, 1457, 5760, 1435, 4102, 771, 3860, 2584, 7417, 1546, 5400, 4998, 7303, 55, 3, 771, 3863, 258, 2811, 6896, 46, 1457, 4368, 517, 6188, 7245, 54, 1457, 6116, 3175, 5330, 5760, 921, 517, 7313, 5377, 7018, 54, 3, 3093, 46, 1370, 5859, 1865, 7096, 1544, 7245, 54, 3, 1435, 1457, 6022, 4832, 6812, 7784, 1546, 5585, 2186, 6023, 5, 3, 1577, 4213, 2936, 2229, 6855, 258, 3, 3093, 3612, 46, 1435, 5130, 7848, 6386, 5400, 54, 3, 3166, 5405, 6855, 46, 3257, 5760, 5112, 6999, 7126, 46, 2892, 7126, 46, 2068, 6999, 7126, 2923, 5439, 1235, 6999, 7126, 7096, 6022, 4737, 6999, 7126, 3803, 7788, 3803, 6999, 7126, 2923, 6855, 54, 3, 4012, 6398, 2265, 1225, 6844, 258, 3, 3097, 46, 517, 7028, 6999, 7126, 46, 1235, 6999, 7126, 46, 4737, 6999, 7126, 3803, 7848, 54, 3, 1185, 5377, 2604, 4209, 5850, 517, 492, 492, 54, 3, 517, 7898, 5340, 6060, 629, 18, 3, 1435, 781, 2872, 3862, 6198, 3245, 5330, 4204, 7088, 5591, 258, 3]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "decoded tokens: ['[CLS]', 'â–ê·¸', 'ê²Œ', 'â–ë„ˆ', 'í•œí…Œ', 'â–ë¬¸ì œ', 'ë˜ì§€', 'â–ì•Šì•˜', 'ìœ¼ë©´', 'â–ì¢‹', 'ê² ', 'ì–´', '.', '[SEP]', 'â–ì•„ë‹ˆ', ',', 'â–ê·¼', 'ë°', 'â–ë‚œ', 'â–ë¬¸ì', 'ë¡œ', 'â–ì‚¬ì§„ì„', 'â–ë°›ì„', 'â–ìˆ˜ë„', 'â–ë³´', 'ë‚¼', 'â–ìˆ˜ë„', 'â–ì—†ì–´', '...', 'ì§„ì§œ', 'â–', 'ë³„ë¡œ', 'ì•¼', '.', '[SEP]', 'â–ë„¤', 'ê°€', 'â–ì‹œê°„ì´', 'â–ë‚˜', 'ê³ ', 'â–ì ', 'ê¹', 'â–ì–˜ê¸°', 'í•˜ê³ ', 'â–', 'ì‹¶', 'ìœ¼ë©´', 'â–ì•Œë ¤', 'ì¤˜', ',', 'â–ë‚˜', 'â–ì‹œê°„', 'â–ì¢€', 'â–ìˆì–´', '...', '[SEP]', 'â–ë°©', 'ê¸ˆ', 'â–ì˜í™”', 'ê´€', 'ì—', 'â–ë„ì°©', 'í–ˆ', 'ì–´', '.', '[SEP]', 'â–ì•Œ', 'ê² ', 'ì–´', ',', 'â–ê±±ì •', 'â–ë§ˆ', '.', '[SEP]', 'â–ì•ˆ', 'ë…•', 'â–', '^', '_', '^', '[SEP]', 'â–ì•ˆ', 'ë…•', ',', 'â–ì˜', 'â–ì§€ë‚´', '?', '[SEP]', 'â–ê´œì°®', 'ì•„', '.', 'â–ë°©', 'ê¸ˆ', 'â–ì „ì—', 'â–ì§‘', 'ì—', 'â–', 'ì™”', 'ì–´', '.', '[SEP]', 'â–ì•Œ', 'ê² ', 'ì–´', ',', 'â–ë‚˜', 'â–ì§€ê¸ˆ', 'â–ê³ ê°ë“¤', 'ê³¼', 'â–ì €ë…', 'â–ë¨¹ê³ ', 'â–ìˆì–´', '.', 'â–ë„¤', 'ê°€', 'â–ì—¬ê¸°', 'â–ìˆìœ¼ë©´', 'â–ì¢‹ê² ë‹¤', '.', '[SEP]', 'â–ì•„', 'â–ì•Œ', 'ê² ', 'ì–´', ',', 'â–ë¯¸', 'ì•ˆ', ',', 'â–ë„ˆ', 'â–ë°©', 'í•´', 'í•˜ê³ ', 'â–', 'ì‹¶', 'ì§€', 'â–ì•Šì•„', '!', 'â–ë‚˜', 'ë„', 'â–', 'ê·¸ë˜', '.', '[SEP]', 'â–ì•„ë‹ˆ', 'ì•¼', 'â–ê´œì°®', 'ì•„', ',', 'â–ë„ˆ', 'â–ìƒê°', 'í•˜ê³ ', 'â–ìˆì–´', '.', '[SEP]', 'â–ë‚œ', 'â–í•­ìƒ', 'â–ë„¤', 'â–ë¬¸ì', 'â–ë°›ëŠ”', 'â–ê²Œ', 'â–ê¸°ëŒ€', 'ë¼', '.', '[SEP]', 'â–ì •ë§', 'ì´', 'ì•¼', '?', 'â–ë‚˜ëŠ”', 'â–ë„¤', 'ê°€', 'â–ë°”', 'ì˜', 'ë‹ˆê¹Œ', 'â–ë‚´ê°€', 'â–ê·€', 'ì°®', 'ê²Œ', 'â–í•˜ëŠ”', 'â–ê²ƒ', 'â–ê°™ì•„', 'â–ëŠê»´', 'ì ¸', '.', '[SEP]', 'â–ì‘', 'â–í•­ìƒ', '!', 'â–ë‚˜', 'â–ë°”', 'ì˜', 'ì§€ë§Œ', 'â–ë„¤', 'â–ë¬¸ì', 'â–ë³´ëŠ”', 'â–ê²Œ', 'â–í•­ìƒ', 'â–ê¸°ëŒ€', 'ë¼', '.', '[SEP]', 'â–ì•„', ',', 'â–ë„ˆ', 'â–ì •ë§', 'â–ë‹¤', 'ì •', 'í•˜ë‹¤', 'â–:', ')', '[SEP]', 'â–ê·¸ëƒ¥', 'â–', 'ì†”', 'ì§', 'í•˜ê²Œ', 'â–ë§', 'í•˜ëŠ”', 'â–ê±°', 'ì•¼', '.', '[SEP]', 'â–ë„ˆ', 'â–ì™„ë²½í•œ', 'â–ë‚¨ì', 'â–ê°™ì•„', '.', '[SEP]', 'â–ê·¸ë ‡ê²Œ', 'â–ë§í•´', 'ì¤˜', 'ì„œ', 'â–ê³ ', 'ë§ˆ', 'ì›Œ', '.', 'â–ê·¸ëƒ¥', 'â–ë‚˜', 'ë‹µ', 'ê²Œ', 'â–ìˆëŠ”', 'â–ê±°', 'ì•¼', '.', 'â–ë‚œ', 'â–ë„¤', 'ê°€', 'â–ì •ë§', 'â–ì¢‹ì•„', '.', '[SEP]', 'â–ë‚˜', 'ë„', 'â–ë„ˆ', 'â–ì¢‹ì•„', 'í•´', '.', 'â–ë„ˆ', 'ëŠ”', 'â–ë‚´ê°€', 'â–ì •ë§', 'â–ê°€ì¹˜', 'â–ìˆëŠ”', 'â–ì‚¬ëŒ', 'ì²˜ëŸ¼', 'â–ëŠë¼', 'ê²Œ', 'â–í•´', 'ì¤˜', '...', '[SEP]', 'â–ê°€ì¹˜', 'â–ìˆë‹¤ê³ ', '?', 'â–ì„¸ìƒ', 'ì—', ',', 'â–ë„ˆ', 'â–ì§„ì§œ', 'â–', 'ë©‹', 'ì ¸', '.', 'â–ë„ˆ', 'ë¥¼', 'â–ì•Œì•„', 'ê°€', 'ëŠ”', 'â–ê²Œ', 'â–', 'ì¦', 'ê±°', 'ì›Œ', '.', '[SEP]', 'â–ì•„', ',', 'â–ë‚˜', 'ë„', 'â–ë˜‘ê°™', 'ì´', 'â–ëŠê»´', 'ì ¸', '.', '[SEP]', 'â–ë‚´ê°€', 'â–ë„ˆ', 'ë‘', 'â–í¸', 'ì•ˆ', 'í•˜ê²Œ', 'â–ëŠë¼', 'ê¸¸', 'â–ë°”', 'ë˜', '!', '[SEP]', 'â–ë‹¤ìŒ', 'â–ì£¼', 'â–ìŠ¤ì¼€ì¤„', 'â–ë°›ì•˜', 'ì–´', '?', '[SEP]', 'â–ì•„', 'â–ì‘', ',', 'â–ë‚´ê°€', 'â–í™•ì¸', 'í•´', 'ë³¼', 'ê²Œ', '.', '[SEP]', 'â–ì•Œ', 'ê² ', 'ì–´', ',', 'â–ì—„ë§ˆ', 'ëŠ”', 'â–í™”', 'ìš”', 'ì¼', ',', 'â–ìˆ˜ìš”', 'ì¼', ',', 'â–ëª©', 'ìš”', 'ì¼', 'â–ì‰¬', 'ê³ ', 'â–ê¸ˆ', 'ìš”', 'ì¼', 'ì´', 'ë‘', 'â–í† ', 'ìš”', 'ì¼', 'â–ì¼', 'í•˜ê³ ', 'â–ì¼', 'ìš”', 'ì¼', 'â–ì‰¬', 'ì–´', '.', '[SEP]', 'â–ì „', 'ë¶€', 'â–ë°¤', 'â–ê·¼ë¬´', 'ì•¼', '?', '[SEP]', 'â–ì•„ë‹ˆ', ',', 'â–', 'ì›”', 'ìš”', 'ì¼', ',', 'â–ê¸ˆ', 'ìš”', 'ì¼', ',', 'â–í† ', 'ìš”', 'ì¼', 'â–ì¼', 'í•´', '.', '[SEP]', 'â–ê·¸', 'ê±°', 'â–ì‚¬ì‹¤', 'â–ì¢‹ì€', 'ë°', 'â–', 'á„', 'á„', '.', '[SEP]', 'â–', 'í—·', 'ê°ˆ', 'ë ¤', 'â–:', '(', '[SEP]', 'â–ë‚´ê°€', 'â–ê°ˆ', 'â–ìˆ˜', 'â–ìˆë‹¤', 'ë©´', 'â–ì–¸ì œ', 'ê°€', 'â–ì¢‹', 'ì„', 'ê¹Œ', '?', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(data):\n",
    "    return tokenizer(\n",
    "        data['text'],\n",
    "        add_special_tokens=False,   # ì´ë¯¸ [CLS], [SEP] ì¶”ê°€ë¨\n",
    "        max_length=512,             # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´\n",
    "        truncation=True,            # ë¬¸ì¥ì´ max_lengthë³´ë‹¤ ê¸¸ë©´ ìë¦„\n",
    "        padding=True                # ë¬¸ì¥ì´ max_lengthë³´ë‹¤ ì§§ìœ¼ë©´ padding\n",
    "    )\n",
    "\n",
    "# ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ì— ëŒ€í•´ í† í°í™” ìˆ˜í–‰\n",
    "tokenized_output = tokenize_function(train_data.iloc[0])\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"input_ids: {tokenized_output['input_ids']}\")\n",
    "print(f\"token_type_ids: {tokenized_output['token_type_ids']}\")\n",
    "print(f\"attention_mask: {tokenized_output['attention_mask']}\")\n",
    "print(f\"decoded tokens: {tokenizer.convert_ids_to_tokens(tokenized_output['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8250, 2) (1034, 2) (1024, 2)\n"
     ]
    }
   ],
   "source": [
    "# ê²€ì¦(Vaildation) ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "print(train_data.shape, valid_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/8250 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8250/8250 [00:04<00:00, 1681.39 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1034/1034 [00:00<00:00, 1788.30 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 1577.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset ìƒì„±\n",
    "train_dataset = Dataset.from_pandas(train_data) # pandas DataFrame -> Hugging Face Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "valid_dataset = Dataset.from_pandas(valid_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "datasets = DatasetDict({'train': train_dataset, 'valid': valid_dataset, 'test': test_dataset}) # train, valid, test ë°ì´í„°ì…‹ì„ ë¬¶ì–´ì„œ ì €ì¥\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True) # train, vaild, test ë°ì´í„°ì…‹ì— tokenize_function ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 8250\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1034\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1024\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "model_save_path = '../models/model_save'\n",
    "\n",
    "# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_save_path,                 # í•™ìŠµ ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "    report_to='wandb',                          # wandb ì‚¬ìš©\n",
    "    num_train_epochs=15,                        # í•™ìŠµ epoch ì„¤ì •\n",
    "    per_device_train_batch_size=32,             # train batch_size ì„¤ì •\n",
    "    per_device_eval_batch_size=32,              # test batch_size ì„¤ì •\n",
    "    logging_dir=model_save_path+'/logs',        # í•™ìŠµ log ì €ì¥ ê²½ë¡œ\n",
    "    logging_steps=100,                          # í•™ìŠµ log ê¸°ë¡ ë‹¨ìœ„\n",
    "    save_total_limit=2,                         # í•™ìŠµ ê²°ê³¼ ì €ì¥ ìµœëŒ€ ê°œìˆ˜\n",
    "    evaluation_strategy=\"epoch\",                # ë§¤ epochë§ˆë‹¤ í‰ê°€ ì‹¤í–‰\n",
    "    save_strategy=\"epoch\",                      # ë§¤ epochë§ˆë‹¤ ëª¨ë¸ ì €ì¥\n",
    "    load_best_model_at_end=True,                # ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ì„ ë§ˆì§€ë§‰ì— load\n",
    ")\n",
    "\n",
    "# ìµœì í™” ì•Œê³ ë¦¬ì¦˜(optimizer) ì„¤ì •\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# # ìŠ¤ì¼€ì¤„ëŸ¬(scheduler) ì„¤ì •\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=len(tokenized_datasets['train']) * training_args.num_train_epochs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ì„¤ì •(binary classification)\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, None),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ\n",
    "model_checkpoint = \"../models/kobert_finetuning\"\n",
    "\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "model = BertForSequenceClassification.from_pretrained(model_checkpoint).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13740025460720062,\n",
       " 'eval_model_preparation_time': 0.002,\n",
       " 'eval_accuracy': 0.9755859375,\n",
       " 'eval_f1': 0.9856569133677567,\n",
       " 'eval_precision': 0.983963344788087,\n",
       " 'eval_recall': 0.9873563218390805,\n",
       " 'eval_runtime': 10.6301,\n",
       " 'eval_samples_per_second': 96.33,\n",
       " 'eval_steps_per_second': 3.01}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸(Test) ë°ì´í„°ì…‹ í‰ê°€\n",
    "trainer.evaluate(tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding Window('\\t' ver.)\n",
    "def preprocess(texts):\n",
    "    text = \"[CLS] \" + \" \".join(str(m) + \" [SEP]\" for m in texts)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤ì œ ëŒ€í™” í…ŒìŠ¤íŠ¸\n",
    "def predict(chat):\n",
    "    model.eval()\n",
    "    tokenized_sent = tokenizer(\n",
    "        chat,\n",
    "        add_special_tokens=False,   # ì´ë¯¸ [CLS], [SEP] ì¶”ê°€ë¨\n",
    "        max_length=512,             # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´\n",
    "        truncation=True,            # ë¬¸ì¥ì´ max_lengthë³´ë‹¤ ê¸¸ë©´ ìë¦„\n",
    "        padding=True,               # ë¬¸ì¥ì´ max_lengthë³´ë‹¤ ì§§ìœ¼ë©´ padding\n",
    "        return_tensors='pt'         # PyTorch tensorë¡œ ë°˜í™˜\n",
    "    )\n",
    "    tokenized_sent.to('cuda')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "            )\n",
    "        \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)  \n",
    "    \n",
    "    if result == 0:\n",
    "        return 'ì¼ìƒ ëŒ€í™” ğŸ˜‡'\n",
    "    elif result == 1:\n",
    "        return 'ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~\n",
      "ì•„ ì•ˆë¼~\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~\n",
      "ì•„ ì•ˆë¼~\n",
      "ì§€ê¸ˆ ë„ˆë¬´ ê¼´ë ¤ì„œ..\n",
      "[Pred]: ì¼ìƒ ëŒ€í™” ğŸ˜‡\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~\n",
      "ì•„ ì•ˆë¼~\n",
      "ì§€ê¸ˆ ë„ˆë¬´ ê¼´ë ¤ì„œ..\n",
      "ë¯¸ì•ˆí•´..\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~\n",
      "ì•„ ì•ˆë¼~\n",
      "ì§€ê¸ˆ ë„ˆë¬´ ê¼´ë ¤ì„œ..\n",
      "ë¯¸ì•ˆí•´..\n",
      "ê·¸ëŸ¼ ë‹´ì— ë‹¤ë¦¬ ì°ì–´ì„œ ë³´ë‚´ì£¼ê¸°ë‹¤~\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n",
      "[Chat]:\n",
      "ì˜¤ëŠ˜ ë­í–ˆì–´?\n",
      "ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´\n",
      "ì˜¤ë¹ ëŠ”?\n",
      "ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´\n",
      "ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´\n",
      "ì™œ?ã…ã…ã…\n",
      "í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ\n",
      "ì•„ ë­ë˜~\n",
      "ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ\n",
      "ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼\n",
      "ì•„ ë¯¸ì•ˆí•´\n",
      "ê·¸ë˜ ìì¤‘í•´~\n",
      "ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!\n",
      "ê·¸ë˜ íŒŒì´íŒ…!!\n",
      "ì˜¤í‚¤~\n",
      "ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~\n",
      "ì•„ ì•ˆë¼~\n",
      "ì§€ê¸ˆ ë„ˆë¬´ ê¼´ë ¤ì„œ..\n",
      "ë¯¸ì•ˆí•´..\n",
      "ê·¸ëŸ¼ ë‹´ì— ë‹¤ë¦¬ ì°ì–´ì„œ ë³´ë‚´ì£¼ê¸°ë‹¤~\n",
      "ì•Œì•˜ì–´~\n",
      "[Pred]: ê·¸ë£¨ë° ëŒ€í™” ğŸ‘¿\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    'ì˜¤ëŠ˜ ë­í–ˆì–´?',\n",
    "    'ì˜¤ëŠ˜ ê·¸ëƒ¥ í•™êµ ê°”ë‹¤ ì™”ì–´',\n",
    "    'ì˜¤ë¹ ëŠ”?',\n",
    "    'ë‚˜ë„ ì˜¤ëŠ˜ ê·¸ëƒ¥ ì§‘ì—ì„œ ì‰¬ì—ˆì–´',\n",
    "    'ê·¼ë° ë„ˆ ìƒê° ë§ì´ ë‚¬ì–´',\n",
    "    'ì™œ?ã…ã…ã…',\n",
    "    'í‚¤ìŠ¤í•˜ê³  ì‹¶ì–´ì„œ',\n",
    "    'ì•„ ë­ë˜~',\n",
    "    'ì™œ í‚¤ìŠ¤ê°€ ì–´ë•Œì„œ',\n",
    "    'ë‚˜ ì•„ì§ ë¯¸ì„±ë…„ìì•¼',\n",
    "    'ì•„ ë¯¸ì•ˆí•´',\n",
    "    'ê·¸ë˜ ìì¤‘í•´~',\n",
    "    'ë‚˜ ê³µë¶€í•˜ê³  ì˜¬ê²Œ!!',\n",
    "    'ê·¸ë˜ íŒŒì´íŒ…!!',\n",
    "    'ì˜¤í‚¤~',\n",
    "    'ì ë§Œ ê°€ê¸° ì „ì— ë‹¤ë¦¬ ì‚¬ì§„ í•œë²ˆë§Œ ë³´ë‚´ì¤˜~',\n",
    "    'ì•„ ì•ˆë¼~',\n",
    "    'ì§€ê¸ˆ ë„ˆë¬´ ê¼´ë ¤ì„œ..',\n",
    "    'ë¯¸ì•ˆí•´..',\n",
    "    'ê·¸ëŸ¼ ë‹´ì— ë‹¤ë¦¬ ì°ì–´ì„œ ë³´ë‚´ì£¼ê¸°ë‹¤~',\n",
    "    'ì•Œì•˜ì–´~'\n",
    "]\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    print(f'[Chat]:')\n",
    "    for j in test[:i+1]:\n",
    "        print(j)\n",
    "    print(f'[Pred]: {predict(preprocess(test[:i+1]))}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
