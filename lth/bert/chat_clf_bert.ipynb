{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AdamW, EarlyStoppingCallback\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moiehhun\u001b[0m (\u001b[33moiehhun-yonsei-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/xogns5037/wandb/run-20250130_115005-47zph67z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z' target=\"_blank\">run1</a></strong> to <a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning' target=\"_blank\">https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z' target=\"_blank\">https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc84f71cca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='chat_clf_bert_finetuning', name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 출처 : https://github.com/songys/Chatbot_data \\\n",
    "데이터 설명 : 11,876개의 한글 대화 문답으로 되어 있는 인공데이터로, 일상 대화, 이별과 관련된 대화, 긍정적인 사랑에 대한 대화가 각각 0, 1, 2로 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = pd.read_csv('./K-CAT/lth/data/ChatbotData.csv',encoding=\"utf-8\")\n",
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "chat_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터셋은 일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링 되어 있음\n",
    "- 일상 대화인지 이별 대화인지 사랑 대화인지 분류하는 문제를 풀기 위해 이별(0)/사랑(1) 레이블을 1로 통합\n",
    "- 일상 대화(0), 연애 대화(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이별, 사랑 label을 1로 통합\n",
    "chat_data.loc[(chat_data['label'] == 2), 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      1\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      1\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      1\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      1\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      1\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 3) (2823, 3)\n"
     ]
    }
   ],
   "source": [
    "# train, test 데이터셋 셔플 및 분리\n",
    "chat_data_suffled = chat_data.sample(frac=1).reset_index(drop=True)\n",
    "train = chat_data_suffled[:9000]\n",
    "test = chat_data_suffled[9000:]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT 모델 불러오기\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT 모델 불러오기\n",
    "tokenizer = BertTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(data):\n",
    "    return tokenizer(\n",
    "        data['Q'], data['A'],       # 대화 내용(Q : A)\n",
    "        add_special_tokens=True,    # [CLS] Q [SEP] A [SEP]\n",
    "        max_length=256,             # 문장 최대 길이\n",
    "        truncation=True,            # 문장이 max_length보다 길면 자름\n",
    "        padding='max_length'        # 문장이 max_length보다 짧으면 padding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: 안녕하세요?\n",
      "A: 반갑습니다!\n",
      "input_ids: [101, 1463, 30006, 30021, 29992, 30010, 30025, 30005, 30006, 29997, 30009, 29999, 30013, 1029, 102, 1460, 30006, 30021, 29991, 30006, 30024, 29997, 30017, 30024, 29992, 30019, 29993, 30006, 999, 102, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "tokens: ['[CLS]', 'ᄋ', '##ᅡ', '##ᆫ', '##ᄂ', '##ᅧ', '##ᆼ', '##ᄒ', '##ᅡ', '##ᄉ', '##ᅦ', '##ᄋ', '##ᅭ', '?', '[SEP]', 'ᄇ', '##ᅡ', '##ᆫ', '##ᄀ', '##ᅡ', '##ᆸ', '##ᄉ', '##ᅳ', '##ᆸ', '##ᄂ', '##ᅵ', '##ᄃ', '##ᅡ', '!', '[SEP]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# tokenize 예시 결과\n",
    "q_text = '안녕하세요?'\n",
    "a_text = '반갑습니다!'\n",
    "\n",
    "tokenized_output = tokenizer(\n",
    "    q_text, a_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=32,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    ")\n",
    "\n",
    "print(f\"Q: {q_text}\")\n",
    "print(f\"A: {a_text}\")\n",
    "print(f\"input_ids: {tokenized_output['input_ids']}\") # tokenized된 문장을 숫자로 표현한 것(id는 vocab에 있는 단어의 index)\n",
    "print(f\"token_type_ids: {tokenized_output['token_type_ids']}\") # 문장 구분을 위한 token_type_ids\n",
    "print(f\"attention_mask: {tokenized_output['attention_mask']}\") # 실제 의미가 있는 token(모델이 참조해야할 부분)은 1, padding(참조하지 않아도 되는 부분)은 0\n",
    "print(f\"tokens: {tokenizer.convert_ids_to_tokens(tokenized_output['input_ids'])}\") # input_ids를 다시 토큰화한 결과 : [CLS] 안녕하세요? [SEP] 반갑습니다! [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8100, 3) (900, 3)\n"
     ]
    }
   ],
   "source": [
    "# 검증(Vaildation) 데이터셋 분리\n",
    "train_data, valid_data = train_test_split(train, test_size=0.1, random_state=42)\n",
    "print(train_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8100/8100 [00:03<00:00, 2648.30 examples/s]\n",
      "Map: 100%|██████████| 900/900 [00:00<00:00, 2287.18 examples/s]\n",
      "Map: 100%|██████████| 2823/2823 [00:01<00:00, 2647.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset 생성\n",
    "train_dataset = Dataset.from_pandas(train_data) # pandas DataFrame -> Hugging Face Dataset 형식으로 변환\n",
    "valid_dataset = Dataset.from_pandas(valid_data)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "datasets = DatasetDict({'train': train_dataset, 'valid': valid_dataset, 'test': test_dataset}) # train, valid, test 데이터셋을 묶어서 저장\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True) # train, vaild, test 데이터셋에 tokenize_function 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Q', 'A', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 8100\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['Q', 'A', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Q', 'A', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2823\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 학습 파라미터 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./K-CAT/lth/model_save',        # 학습 결과 저장 경로\n",
    "    report_to='wandb',                          # wandb 사용\n",
    "    num_train_epochs=15,                        # 학습 epoch 설정\n",
    "    per_device_train_batch_size=32,             # train batch_size 설정\n",
    "    per_device_eval_batch_size=32,              # test batch_size 설정\n",
    "    logging_dir='./K-CAT/lth/model_save/logs',  # 학습 log 저장 경로\n",
    "    logging_steps=100,                          # 학습 log 기록 단위\n",
    "    save_total_limit=2,                         # 학습 결과 저장 최대 개수\n",
    "    evaluation_strategy=\"epoch\",                # 매 epoch마다 평가 실행\n",
    "    save_strategy=\"epoch\",                      # 매 epoch마다 모델 저장\n",
    "    load_best_model_at_end=True,                # 가장 성능이 좋은 모델을 마지막에 load\n",
    ")\n",
    "\n",
    "# 최적화 알고리즘(optimizer) 설정\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# 스케줄러(scheduler) 설정\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(tokenized_datasets['train']) * training_args.num_train_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 평가 지표 설정(binary classification)\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer 생성\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2032' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2032/3810 23:25 < 20:31, 1.44 it/s, Epoch 8/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547100</td>\n",
       "      <td>0.454222</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.806154</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.789157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.436502</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.706827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.398262</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.850895</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.439206</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.834061</td>\n",
       "      <td>0.913876</td>\n",
       "      <td>0.767068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.418377</td>\n",
       "      <td>0.837778</td>\n",
       "      <td>0.845992</td>\n",
       "      <td>0.891111</td>\n",
       "      <td>0.805221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.433498</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.848801</td>\n",
       "      <td>0.882863</td>\n",
       "      <td>0.817269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.447833</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.852590</td>\n",
       "      <td>0.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.482568</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.860324</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.853414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2032, training_loss=0.32180882157303214, metrics={'train_runtime': 1409.1302, 'train_samples_per_second': 86.223, 'train_steps_per_second': 2.704, 'total_flos': 8524798193664000.0, 'train_loss': 0.32180882157303214, 'epoch': 8.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4072250425815582,\n",
       " 'eval_accuracy': 0.824300389656394,\n",
       " 'eval_f1': 0.8411274823830878,\n",
       " 'eval_precision': 0.8357733927434755,\n",
       " 'eval_recall': 0.8465506125080593,\n",
       " 'eval_runtime': 20.9911,\n",
       " 'eval_samples_per_second': 134.486,\n",
       " 'eval_steps_per_second': 4.24,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트(Test) 데이터셋 평가\n",
    "trainer.evaluate(tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Q: 사랑의 유효기간\n",
      " A: 이별의 유통기한이 없는 것처럼 사랑의 유효기간도 없어요.\n",
      " label: 1\n",
      " pred: 연애 대화 🥰\n",
      "\n",
      " Q: 술취해서 전화했어\n",
      " A: 후회하지 않을까요.\n",
      " label: 1\n",
      " pred: 일상 대화 🤖\n",
      "\n",
      " Q: 좋아하는 사람이랑 종교가 다른데 괜찮을까?\n",
      " A: 종교가 큰 문제가 되기도 하죠.\n",
      " label: 1\n",
      " pred: 연애 대화 🥰\n",
      "\n",
      " Q: 이별후 너무 외로워ㅠ\n",
      " A: 이별의 빈자리가 느껴지니까요.\n",
      " label: 1\n",
      " pred: 연애 대화 🥰\n",
      "\n",
      " Q: 나 미팅한다!\n",
      " A: 성공을 기원합니다.\n",
      " label: 0\n",
      " pred: 일상 대화 🤖\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mrun1\u001b[0m at: \u001b[34mhttps://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250130_115005-47zph67z/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 실제 대화 테스트\n",
    "def predict(q, a):\n",
    "    model.eval()\n",
    "    tokenized_sent = tokenizer(q, a, add_special_tokens=True, return_tensors='pt')\n",
    "    tokenized_sent.to('cuda:0')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "            )\n",
    "        \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)  \n",
    "    \n",
    "    if result == 0:\n",
    "        return '일상 대화 🤖'\n",
    "    elif result == 1:\n",
    "        return '연애 대화 🥰'\n",
    "\n",
    "for idx in range(1, 6):\n",
    "    q = test_dataset[idx]['Q']\n",
    "    a = test_dataset[idx]['A']\n",
    "    label = test_dataset[idx]['label']\n",
    "    print(f' Q: {q}\\n A: {a}\\n label: {label}\\n pred: {predict(q, a)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktflyai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
