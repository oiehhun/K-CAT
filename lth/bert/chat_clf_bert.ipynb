{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AdamW, EarlyStoppingCallback\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moiehhun\u001b[0m (\u001b[33moiehhun-yonsei-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/xogns5037/wandb/run-20250130_115005-47zph67z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z' target=\"_blank\">run1</a></strong> to <a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning' target=\"_blank\">https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z' target=\"_blank\">https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fc84f71cca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='chat_clf_bert_finetuning', name='run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì¶œì²˜ : https://github.com/songys/Chatbot_data \\\n",
    "ë°ì´í„° ì„¤ëª… : 11,876ê°œì˜ í•œê¸€ ëŒ€í™” ë¬¸ë‹µìœ¼ë¡œ ë˜ì–´ ìˆëŠ” ì¸ê³µë°ì´í„°ë¡œ, ì¼ìƒ ëŒ€í™”, ì´ë³„ê³¼ ê´€ë ¨ëœ ëŒ€í™”, ê¸ì •ì ì¸ ì‚¬ë‘ì— ëŒ€í•œ ëŒ€í™”ê°€ ê°ê° 0, 1, 2ë¡œ ë¼ë²¨ë§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.</td>\n",
       "      <td>ì„¤ë œê² ì–´ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?</td>\n",
       "      <td>ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´</td>\n",
       "      <td>ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12ì‹œ ë•¡!                í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1                  1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´                 ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2                 3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤               ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3              3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤               ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4                      PPL ì‹¬í•˜ë„¤                ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0\n",
       "...                        ...                       ...    ...\n",
       "11818           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.        í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !      2\n",
       "11819           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.             í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.      2\n",
       "11820              í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.                    ì„¤ë œê² ì–´ìš”.      2\n",
       "11821  í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?  ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.      2\n",
       "11822               í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´        ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = pd.read_csv('./K-CAT/lth/data/ChatbotData.csv',encoding=\"utf-8\")\n",
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11823 entries, 0 to 11822\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       11823 non-null  object\n",
      " 1   A       11823 non-null  object\n",
      " 2   label   11823 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 277.2+ KB\n"
     ]
    }
   ],
   "source": [
    "chat_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ë°ì´í„°ì…‹ì€ ì¼ìƒë‹¤ë°˜ì‚¬ 0, ì´ë³„(ë¶€ì •) 1, ì‚¬ë‘(ê¸ì •) 2ë¡œ ë ˆì´ë¸”ë§ ë˜ì–´ ìˆìŒ\n",
    "- ì¼ìƒ ëŒ€í™”ì¸ì§€ ì´ë³„ ëŒ€í™”ì¸ì§€ ì‚¬ë‘ ëŒ€í™”ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œë¥¼ í’€ê¸° ìœ„í•´ ì´ë³„(0)/ì‚¬ë‘(1) ë ˆì´ë¸”ì„ 1ë¡œ í†µí•©\n",
    "- ì¼ìƒ ëŒ€í™”(0), ì—°ì•  ëŒ€í™”(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì´ë³„, ì‚¬ë‘ labelì„ 1ë¡œ í†µí•©\n",
    "chat_data.loc[(chat_data['label'] == 2), 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.</td>\n",
       "      <td>í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.</td>\n",
       "      <td>ì„¤ë œê² ì–´ìš”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?</td>\n",
       "      <td>ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´</td>\n",
       "      <td>ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12ì‹œ ë•¡!                í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1                  1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´                 ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2                 3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤               ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3              3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤               ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4                      PPL ì‹¬í•˜ë„¤                ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0\n",
       "...                        ...                       ...    ...\n",
       "11818           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.        í‹°ê°€ ë‚˜ë‹ˆê¹Œ ëˆˆì¹˜ê°€ ë³´ì´ëŠ” ê±°ì£ !      1\n",
       "11819           í›”ì³ë³´ëŠ” ê²ƒë„ ëˆˆì¹˜ ë³´ì„.             í›”ì³ë³´ëŠ” ê±° í‹°ë‚˜ë‚˜ë´ìš”.      1\n",
       "11820              í‘ê¸°ì‚¬ í•´ì£¼ëŠ” ì§ë‚¨.                    ì„¤ë œê² ì–´ìš”.      1\n",
       "11821  í˜ë“  ì—°ì•  ì¢‹ì€ ì—°ì• ë¼ëŠ”ê²Œ ë¬´ìŠ¨ ì°¨ì´ì¼ê¹Œ?  ì˜ í—¤ì–´ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ì´ ì—¬ë¶€ì¸ ê±° ê°™ì•„ìš”.      1\n",
       "11822               í˜ë“¤ì–´ì„œ ê²°í˜¼í• ê¹Œë´        ë„í”¼ì„± ê²°í˜¼ì€ í•˜ì§€ ì•Šê¸¸ ë°”ë¼ìš”.      1\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 3) (2823, 3)\n"
     ]
    }
   ],
   "source": [
    "# train, test ë°ì´í„°ì…‹ ì…”í”Œ ë° ë¶„ë¦¬\n",
    "chat_data_suffled = chat_data.sample(frac=1).reset_index(drop=True)\n",
    "train = chat_data_suffled[:9000]\n",
    "test = chat_data_suffled[9000:]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "tokenizer = BertTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(data):\n",
    "    return tokenizer(\n",
    "        data['Q'], data['A'],       # ëŒ€í™” ë‚´ìš©(Q : A)\n",
    "        add_special_tokens=True,    # [CLS] Q [SEP] A [SEP]\n",
    "        max_length=256,             # ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´\n",
    "        truncation=True,            # ë¬¸ì¥ì´ max_lengthë³´ë‹¤ ê¸¸ë©´ ìë¦„\n",
    "        padding='max_length'        # ë¬¸ì¥ì´ max_lengthë³´ë‹¤ ì§§ìœ¼ë©´ padding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: ì•ˆë…•í•˜ì„¸ìš”?\n",
      "A: ë°˜ê°‘ìŠµë‹ˆë‹¤!\n",
      "input_ids: [101, 1463, 30006, 30021, 29992, 30010, 30025, 30005, 30006, 29997, 30009, 29999, 30013, 1029, 102, 1460, 30006, 30021, 29991, 30006, 30024, 29997, 30017, 30024, 29992, 30019, 29993, 30006, 999, 102, 0, 0]\n",
      "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "tokens: ['[CLS]', 'á„‹', '##á…¡', '##á†«', '##á„‚', '##á…§', '##á†¼', '##á„’', '##á…¡', '##á„‰', '##á…¦', '##á„‹', '##á…­', '?', '[SEP]', 'á„‡', '##á…¡', '##á†«', '##á„€', '##á…¡', '##á†¸', '##á„‰', '##á…³', '##á†¸', '##á„‚', '##á…µ', '##á„ƒ', '##á…¡', '!', '[SEP]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# tokenize ì˜ˆì‹œ ê²°ê³¼\n",
    "q_text = 'ì•ˆë…•í•˜ì„¸ìš”?'\n",
    "a_text = 'ë°˜ê°‘ìŠµë‹ˆë‹¤!'\n",
    "\n",
    "tokenized_output = tokenizer(\n",
    "    q_text, a_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=32,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    ")\n",
    "\n",
    "print(f\"Q: {q_text}\")\n",
    "print(f\"A: {a_text}\")\n",
    "print(f\"input_ids: {tokenized_output['input_ids']}\") # tokenizedëœ ë¬¸ì¥ì„ ìˆ«ìë¡œ í‘œí˜„í•œ ê²ƒ(idëŠ” vocabì— ìˆëŠ” ë‹¨ì–´ì˜ index)\n",
    "print(f\"token_type_ids: {tokenized_output['token_type_ids']}\") # ë¬¸ì¥ êµ¬ë¶„ì„ ìœ„í•œ token_type_ids\n",
    "print(f\"attention_mask: {tokenized_output['attention_mask']}\") # ì‹¤ì œ ì˜ë¯¸ê°€ ìˆëŠ” token(ëª¨ë¸ì´ ì°¸ì¡°í•´ì•¼í•  ë¶€ë¶„)ì€ 1, padding(ì°¸ì¡°í•˜ì§€ ì•Šì•„ë„ ë˜ëŠ” ë¶€ë¶„)ì€ 0\n",
    "print(f\"tokens: {tokenizer.convert_ids_to_tokens(tokenized_output['input_ids'])}\") # input_idsë¥¼ ë‹¤ì‹œ í† í°í™”í•œ ê²°ê³¼ : [CLS] ì•ˆë…•í•˜ì„¸ìš”? [SEP] ë°˜ê°‘ìŠµë‹ˆë‹¤! [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8100, 3) (900, 3)\n"
     ]
    }
   ],
   "source": [
    "# ê²€ì¦(Vaildation) ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
    "train_data, valid_data = train_test_split(train, test_size=0.1, random_state=42)\n",
    "print(train_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8100/8100 [00:03<00:00, 2648.30 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 900/900 [00:00<00:00, 2287.18 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2823/2823 [00:01<00:00, 2647.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Dataset ìƒì„±\n",
    "train_dataset = Dataset.from_pandas(train_data) # pandas DataFrame -> Hugging Face Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "valid_dataset = Dataset.from_pandas(valid_data)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "datasets = DatasetDict({'train': train_dataset, 'valid': valid_dataset, 'test': test_dataset}) # train, valid, test ë°ì´í„°ì…‹ì„ ë¬¶ì–´ì„œ ì €ì¥\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True) # train, vaild, test ë°ì´í„°ì…‹ì— tokenize_function ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Q', 'A', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 8100\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['Q', 'A', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 900\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Q', 'A', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2823\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xogns5037/.conda/envs/sparqlgen/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./K-CAT/lth/model_save',        # í•™ìŠµ ê²°ê³¼ ì €ì¥ ê²½ë¡œ\n",
    "    report_to='wandb',                          # wandb ì‚¬ìš©\n",
    "    num_train_epochs=15,                        # í•™ìŠµ epoch ì„¤ì •\n",
    "    per_device_train_batch_size=32,             # train batch_size ì„¤ì •\n",
    "    per_device_eval_batch_size=32,              # test batch_size ì„¤ì •\n",
    "    logging_dir='./K-CAT/lth/model_save/logs',  # í•™ìŠµ log ì €ì¥ ê²½ë¡œ\n",
    "    logging_steps=100,                          # í•™ìŠµ log ê¸°ë¡ ë‹¨ìœ„\n",
    "    save_total_limit=2,                         # í•™ìŠµ ê²°ê³¼ ì €ì¥ ìµœëŒ€ ê°œìˆ˜\n",
    "    evaluation_strategy=\"epoch\",                # ë§¤ epochë§ˆë‹¤ í‰ê°€ ì‹¤í–‰\n",
    "    save_strategy=\"epoch\",                      # ë§¤ epochë§ˆë‹¤ ëª¨ë¸ ì €ì¥\n",
    "    load_best_model_at_end=True,                # ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ëª¨ë¸ì„ ë§ˆì§€ë§‰ì— load\n",
    ")\n",
    "\n",
    "# ìµœì í™” ì•Œê³ ë¦¬ì¦˜(optimizer) ì„¤ì •\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# ìŠ¤ì¼€ì¤„ëŸ¬(scheduler) ì„¤ì •\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=len(tokenized_datasets['train']) * training_args.num_train_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„±ëŠ¥ í‰ê°€ ì§€í‘œ ì„¤ì •(binary classification)\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2032' max='3810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2032/3810 23:25 < 20:31, 1.44 it/s, Epoch 8/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.547100</td>\n",
       "      <td>0.454222</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.806154</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.789157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.436502</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.791011</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.706827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.398262</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.850895</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>0.439206</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.834061</td>\n",
       "      <td>0.913876</td>\n",
       "      <td>0.767068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.418377</td>\n",
       "      <td>0.837778</td>\n",
       "      <td>0.845992</td>\n",
       "      <td>0.891111</td>\n",
       "      <td>0.805221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.433498</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.848801</td>\n",
       "      <td>0.882863</td>\n",
       "      <td>0.817269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.447833</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.852590</td>\n",
       "      <td>0.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.482568</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.860324</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.853414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2032, training_loss=0.32180882157303214, metrics={'train_runtime': 1409.1302, 'train_samples_per_second': 86.223, 'train_steps_per_second': 2.704, 'total_flos': 8524798193664000.0, 'train_loss': 0.32180882157303214, 'epoch': 8.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4072250425815582,\n",
       " 'eval_accuracy': 0.824300389656394,\n",
       " 'eval_f1': 0.8411274823830878,\n",
       " 'eval_precision': 0.8357733927434755,\n",
       " 'eval_recall': 0.8465506125080593,\n",
       " 'eval_runtime': 20.9911,\n",
       " 'eval_samples_per_second': 134.486,\n",
       " 'eval_steps_per_second': 4.24,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸(Test) ë°ì´í„°ì…‹ í‰ê°€\n",
    "trainer.evaluate(tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Q: ì‚¬ë‘ì˜ ìœ íš¨ê¸°ê°„\n",
      " A: ì´ë³„ì˜ ìœ í†µê¸°í•œì´ ì—†ëŠ” ê²ƒì²˜ëŸ¼ ì‚¬ë‘ì˜ ìœ íš¨ê¸°ê°„ë„ ì—†ì–´ìš”.\n",
      " label: 1\n",
      " pred: ì—°ì•  ëŒ€í™” ğŸ¥°\n",
      "\n",
      " Q: ìˆ ì·¨í•´ì„œ ì „í™”í–ˆì–´\n",
      " A: í›„íšŒí•˜ì§€ ì•Šì„ê¹Œìš”.\n",
      " label: 1\n",
      " pred: ì¼ìƒ ëŒ€í™” ğŸ¤–\n",
      "\n",
      " Q: ì¢‹ì•„í•˜ëŠ” ì‚¬ëŒì´ë‘ ì¢…êµê°€ ë‹¤ë¥¸ë° ê´œì°®ì„ê¹Œ?\n",
      " A: ì¢…êµê°€ í° ë¬¸ì œê°€ ë˜ê¸°ë„ í•˜ì£ .\n",
      " label: 1\n",
      " pred: ì—°ì•  ëŒ€í™” ğŸ¥°\n",
      "\n",
      " Q: ì´ë³„í›„ ë„ˆë¬´ ì™¸ë¡œì›Œã… \n",
      " A: ì´ë³„ì˜ ë¹ˆìë¦¬ê°€ ëŠê»´ì§€ë‹ˆê¹Œìš”.\n",
      " label: 1\n",
      " pred: ì—°ì•  ëŒ€í™” ğŸ¥°\n",
      "\n",
      " Q: ë‚˜ ë¯¸íŒ…í•œë‹¤!\n",
      " A: ì„±ê³µì„ ê¸°ì›í•©ë‹ˆë‹¤.\n",
      " label: 0\n",
      " pred: ì¼ìƒ ëŒ€í™” ğŸ¤–\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;34mwandb\u001b[0m: ğŸš€ View run \u001b[33mrun1\u001b[0m at: \u001b[34mhttps://wandb.ai/oiehhun-yonsei-university/chat_clf_bert_finetuning/runs/47zph67z\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250130_115005-47zph67z/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì œ ëŒ€í™” í…ŒìŠ¤íŠ¸\n",
    "def predict(q, a):\n",
    "    model.eval()\n",
    "    tokenized_sent = tokenizer(q, a, add_special_tokens=True, return_tensors='pt')\n",
    "    tokenized_sent.to('cuda:0')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=tokenized_sent[\"input_ids\"],\n",
    "            attention_mask=tokenized_sent[\"attention_mask\"],\n",
    "            token_type_ids=tokenized_sent[\"token_type_ids\"]\n",
    "            )\n",
    "        \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu()\n",
    "    result = logits.argmax(-1)  \n",
    "    \n",
    "    if result == 0:\n",
    "        return 'ì¼ìƒ ëŒ€í™” ğŸ¤–'\n",
    "    elif result == 1:\n",
    "        return 'ì—°ì•  ëŒ€í™” ğŸ¥°'\n",
    "\n",
    "for idx in range(1, 6):\n",
    "    q = test_dataset[idx]['Q']\n",
    "    a = test_dataset[idx]['A']\n",
    "    label = test_dataset[idx]['label']\n",
    "    print(f' Q: {q}\\n A: {a}\\n label: {label}\\n pred: {predict(q, a)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktflyai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
