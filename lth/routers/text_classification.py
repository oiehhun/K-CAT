from fastapi import APIRouter
from pydantic import BaseModel
import torch
from transformers import BertForSequenceClassification
from kobert_tokenizer import KoBERTTokenizer
from collections import deque

router = APIRouter(prefix="/text", tags=["Text Classification"])

# ëª¨ë¸ ë¡œë“œ
model_checkpoint = "/home/k-cat/TH/K-CAT/lth/models/kobert_finetuning"
tokenizer = KoBERTTokenizer.from_pretrained("skt/kobert-base-v1")
model = BertForSequenceClassification.from_pretrained(model_checkpoint).to("cuda")
model.eval()

def preprocess(chat):
    return "[CLS] " + " [SEP] ".join(chat) + " [SEP]"

def tokenize_function(text):
    return tokenizer(
        text, add_special_tokens=False, max_length=512, truncation=True, padding="max_length", return_tensors="pt"
    )

# íƒì§€ ê¸°ì¤€ ë° ìœˆë„ìš° ì„¤ì •
skepticism = 3
window_num = 5
window_size = 10
detection_list = deque(maxlen=window_num)
chat_list = deque(maxlen=window_num)

class ChatText(BaseModel):
    text: list[str]

@router.post("/predict/")
async def predict(chat_text: ChatText):
    chat_text = [c.replace('\u200b', '') for c in chat_text.text]
    chat = preprocess(chat_text)
    tokenized_input = tokenize_function(chat)

    inputs = tokenized_input["input_ids"].to("cuda")
    attention_mask = tokenized_input["attention_mask"].to("cuda")

    with torch.no_grad():
        output = model(inputs, attention_mask=attention_mask)
    
    prediction = torch.argmax(output.logits, dim=-1).cpu().item()
    detection_list.append(prediction)
    print("===============ì‹¤ì‹œê°„ ì˜¨ë¼ì¸ ê·¸ë£¨ë° íƒì§€===============")
    print('âœ… ì±„íŒ… ë‚´ìš©:', chat)
    print('âœ… ìµœê·¼ ìœˆë„ìš° ì˜ˆì¸¡:', detection_list)
    print('âœ… í˜„ì¬ ì±„íŒ… ì˜ˆì¸¡:', prediction)
    print()

    # ìœˆë„ìš° í¬ê¸°ë¥¼ ì´ˆê³¼í•  ê²½ìš° ì±„íŒ… ì €ì¥(ìµœê·¼ ìœˆë„ìš° ê°œìˆ˜-1 ë§Œí¼)
    if len(chat_text) == window_size:
        chat_list.append(chat_text[0])

    # íƒì§€ ê¸°ì¤€(skepticism) ì´ˆê³¼ ì‹œ
    if sum(detection_list) >= skepticism:
        # detection_list.clear()    # íƒì§€ ì‹œ deque ì´ˆê¸°í™”
        report_prompt = list(chat_list) + chat_text[1:]
        print('ğŸš¨ í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡!')
        print('âœ… íƒì§€ëœ ìœˆë„ìš° ì±„íŒ…:', report_prompt)
        print()
        return {"prediction": 1, "chat_text": report_prompt}
    
    return {"prediction": 0, "chat_text": None}
